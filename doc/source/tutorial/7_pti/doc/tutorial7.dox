/*!

\page tut7_pti Tutorial 7: Parameter Tuning Interface (PTI)
\tableofcontents
\author Eric O. Scott
\author Kristofor D. Carlson

\see \ref ch10_ecj

\section tut7s1_intro 7.1 Introduction

This tutorial covers the use of evolutionary algorithms to tune the parameters of an SNN in %CARLsim.

CARLsim3 ships with a parameter-tuning framework known affectionately as PTI. PTI essentially provides a class 
that you wrap around your %CARLsim simulation to create a special "black box" program that takes one or more 
vectors of <b>parameters</b> as input (in CSV format), and returns <b>fitness values</b> as output.  This 
interface is used by the <a href="https://cs.gmu.edu/~eclab/projects/ecj/">ECJ evolutionary computation toolkit</a> 
to provide a fitness function for an optimization algorithm.

The evolutionary algorithm won't define the fitness function for you or tell you
 how you should structure your model&mdash;but it can automatically search your parameter space for 
good model configurations.

This tutorial assumes the following:
- %CARLsim 3.1.4 or greater is installed.
- ECJ and the CARLsim-ECJ parameter-tuning interface are installed.
- The <tt>configure.mk</tt> file and associated %CARLsim environment variables are configured correctly.

If you have not yet installed ECJ and the CARLsim-ECJ PTI, see \ref ch10_ecj, or just follow the instructions in
<tt>tools/ecj_pti/README</tt>.



\subsection tut7s11_overview 7.1.1 Code Overview

In this tutorial we tune the weight ranges of a simple SNN to achieve a particular target firing rate.  To do so, 
we must implement the SNN model and define the evolutionary algorithm that will optimize it.  The code for both 
of this components is found in  the <tt>doc/source/tutorial/7_pti</tt> directory, which contains the following:
- <tt>Makefile</tt>: The Makefile used to compile the C++ source file.
- <tt>results/</tt>: A directory that will contain any metadata and results generated by the simulation.
- <tt>src/main_tuneFiringRatesECJ.cpp</tt>: A CARLsim3 model implementation that adheres to the PTI interface specification.
- <tt>src/tuneFiringRatesECJExperiment.params</tt>: An ECJ configuration file, detailing the evolutionary algorithm.

Typing <tt>make</tt> in the shell will compile the C++ code and produce two output files:
- <tt>tuneFiringRatesECJ</tt>: A binary that takes comma-delimited parameter vectors as input (one per line) and returns fitness values (one per line).
- <tt>launchCARLsimECJ.sh</tt>: A convenience script that runs ECJ (and its CARLsim3-specific extentions) using the 
parameters in <tt>src/tuneFiringRatesECJExperiment.params</tt>.

If you have any troubles building the tutorial code, make sure that your environment variables (if necessary) are 
correctly defined in your shell (as discussed in \ref ch1_getting_started) and that the CARLsim-ECJ PTI has been 
installed as described in \ref ch10_ecj.

The remainder of this tutorial will explain the code in the  <tt>main_tuneFiringRatesECJ.cpp</tt> and <tt>tuneFiringRatesECJExperiment.params</tt> 
files, in that order.



\section tut7s2_blackbox 7.2 The Black-Box SNN Simulation

The first step in parameter tuning is to build a version of your model that operates as a "black box."  The 
evolutionary algorithm will use this binary application as a fitness function.  

\subsection tut7s21_model 7.2.1 Setting up the SNN Model

To ensure that we are making the most of CARLsim3's GPU acceleration, our  application will evaluate 
multiple parameterized networks in parallel.  As such, our code for the SNN model differs a bit from previous 
tutorials: we aren't creating just one neural network, but many <i>copies</i> of the same network, each 
with a different parameter configuration.

The layout of each SNN in our example is as follows. We have 10 input excitatory
neurons, 10 regular spiking (RS) excitatory neurons that receive this input, and 10 fast spiking
(FS) Izhikevich neurons that receive input from the excitatory RS neurons. Additionally, the
inhibitory group is connected to the RS excitatory group and the RS excitatory group is connected to
itself recurrently. There are therefore <b>4 connection weight ranges to be tuned</b>. The goal of the
tuning is make the RS excitatory group have an average firing rate of 10 Hz and make the FS
inhibitory group have an average firing rate of 20 Hz.


The standard way to create such a simulation for parameter-tuning in CARLsim3 is to implement Experiment:
\code
class TuneFiringRatesECJExperiment : public Experiment {
public:

TuneFiringRatesECJExperiment() {}
\endcode
Experiment is an 
abstract class that has just one virtual method, <tt>run()</tt>.  This method takes two arguments: 
a ParameterInstances object (which stores a number of candidate parameter vectors), and an output stream
 (<tt>str::ostream</tt>).  Your job is to write a function that converts parameter vectors into fitness 
values, writing one fitness value to the <tt>ostream</tt> for each parameter vector in the input. Here is how 
ours starts:

\code
...
void run(const ParameterInstances &parameters, std::ostream &outputStream) const {
     // Decay constants                                                                                                                                                        
     const float COND_tAMPA=5.0, COND_tNMDA=150.0, COND_tGABAa=6.0, COND_tGABAb=150.0;

     // Neurons                                                                                                                                                                
     const int NUM_NEURONS = 10;

     // Izhikevich parameters                                                                                                                                                  
     const float REG_IZH[] = { 0.02f, 0.2f, -65.0f, 8.0f };
     const float FAST_IZH[] = { 0.1f, 0.2f, -65.0f, 2.0f };

     // Simulation time (each must be at least 1s due to bug in SpikeMonitor)                                                                                                  
     const int runTime = 2;
...
\endcode

These first few lines just set up a number of hard-coded constants that will be a part of our model.  These parameters will 
<i>not</i> be tuned (though we could tune any of them if we liked).

\note Your model may depend on additional configuration parameters that you don't wish to tune, but which you don't wish 
to hard-code into the <tt>run()</tt> method either (such as a file path pointing to external data, or a variable parameter defining, 
say, the number of neurons in the network).

\note If your model needs additional information that isn't found in the provided ParameterInstances, you can add data 
members to your Experiment subclass and <i>use the constructor</i> to initialize them.  You will be manually instantiating 
the <tt>TuneFiringRatesECJExperiment</tt> class in your <tt>main()</tt> method below, so you will have an opportunity to pass data in from command 
line arguments or wherever you like.

Next we define the constants that will control the network's input signal and the target firing rates.  The latter will make up an important 
part of our fitness function.  We also go ahead and create arrays to hold group IDs, SpikeMonitor pointers, and some statistics that 
we will calculate for each network:
\code
...
     // Target rates for the objective function                                                                                                                                
     const float INPUT_TARGET_HZ = 30.0f;
     const float EXC_TARGET_HZ   = 10.0f;
     const float INH_TARGET_HZ   = 20.0f;
     
     int indiNum = parameters.getNumInstances();

     int poissonGroup[indiNum];
     int excGroup[indiNum];
     int inhGroup[indiNum];
     SpikeMonitor* excMonitor[indiNum];
     SpikeMonitor* inhMonitor[indiNum];
     float excHz[indiNum];
     float inhHz[indiNum];
     float excError[indiNum];
     float inhError[indiNum];
     float fitness[indiNum];
...
\endcode

In previous tutorials, we only created one network at a time, so there was no need to create arrays like this.  For parameter tuning, 
however, we want to create many networks at once (each based on a different parameter vector) so that we can evaluate many 
parameter configurations in parallel.  The <tt>parameters.getNumInstances()</tt> tells us how many parameter vectors have been 
provided to our program as input, and thus how many networks we need to build.


\note Technically, CARLsim3 does not allow us to run multiple networks in parallel <i>per se</i>.  What we are going to do, then, is 
combine the groups for each network into one supernetwork.  We will only create connections between groups within the same network, 
however, so executing the supernetwork is equivalent to executing many smaller networks in parallel.

Now we loop through each network to initialize the neuron groups and the connections between them.  For the parameters we are not 
tuning, we simply use the constants that we defined above.  For the parameters that we <i>are</i> tuning (namely the range of the 
connection weights), we use the method <tt>parameters.getParameter(i,j)</tt> to access the <tt>j</tt>th parameter from the 
<tt>i</tt>th parameter vector.

\code
...
/* construct a CARLsim network on the heap. */
#ifdef __NO_CUDA__
       // we cannot use GPU_MODE when compiled with NO_CUDA
       CARLsim* const network = new CARLsim("tuneFiringRatesECJ", CPU_MODE, SILENT);
#else  
       CARLsim* const network = new CARLsim("tuneFiringRatesECJ", GPU_MODE, SILENT);
#endif
       for(unsigned int i = 0; i < parameters.getNumInstances(); i++) {
       		    /** Decode a genome*/
		    poissonGroup[i] = network->createSpikeGeneratorGroup("poisson", NUM_NEURONS, EXCITATORY_NEURON);
		    excGroup[i] = network->createGroup("exc", NUM_NEURONS, EXCITATORY_NEURON);
		    inhGroup[i] = network->createGroup("inh", NUM_NEURONS, INHIBITORY_NEURON);

		    network->setNeuronParameters(excGroup[i], REG_IZH[0], REG_IZH[1], REG_IZH[2], REG_IZH[3]);
		    network->setNeuronParameters(inhGroup[i], FAST_IZH[0], FAST_IZH[1], FAST_IZH[2], FAST_IZH[3]);
		    network->setConductances(true,COND_tAMPA,COND_tNMDA,COND_tGABAa,COND_tGABAb);

		    network->connect(poissonGroup[i], excGroup[i], "random", RangeWeight(parameters.getParameter(i,0)), 0.5f, RangeDelay(1));
		    network->connect(excGroup[i], excGroup[i], "random", RangeWeight(parameters.getParameter(i,1)), 0.5f, RangeDelay(1));
		    network->connect(excGroup[i], inhGroup[i], "random", RangeWeight(parameters.getParameter(i,2)), 0.5f, RangeDelay(1));
		    network->connect(inhGroup[i], excGroup[i], "random", RangeWeight(parameters.getParameter(i,3)), 0.5f, RangeDelay(1));
	}
...
\endcode

With all the networks configured, we can call <tt>setupNetwork()</tt> and then iterate through the 
subnetworks one more time to attach SpikeMonitor objects.  These probes will gather the information that we 
need to calculate fitness.

\code
...
	network->setupNetwork();

	// it's unnecessary to do this in the loop                                                                                                                                
	PoissonRate* const in = new PoissonRate(NUM_NEURONS);
	in->setRates(INPUT_TARGET_HZ);

	for(unsigned int i = 0; i < parameters.getNumInstances(); i++) {
		     network->setSpikeRate(poissonGroup[i],in);

		     excMonitor[i] = network->setSpikeMonitor(excGroup[i], "/dev/null");
		     inhMonitor[i] = network->setSpikeMonitor(inhGroup[i], "/dev/null");

		     excMonitor[i]->startRecording();
		     inhMonitor[i]->startRecording();

		     // initialize all the error and fitness variables                                                                                                                 
		     excHz[i]=0; inhHz[i]=0;
		     excError[i]=0; inhError[i]=0;
		     fitness[i]=0;
	}
...
\endcode
Finally, this leaves us with one giant supernetwork that we can run in the usual way:

\code
...
	network->runNetwork(runTime,0);
...
\endcode

\subsection tut7s22_fitness 7.2.2 Setting up the Fitness Function

After the network runs, we need to collect the results and compute a fitness value for each network. 
We also do this inside the <tt>run()</tt> method.

There are many ways to define a fitness function, and it's often a good idea to think carefully about 
how to craft a fitness function that captures your scientific objectives.  For our example here, we 
use the following function: for a given network built from parameter vector \f$\vec{x}\f$, let 
\f$r_{\texttt{exc}}, r_{\texttt{inh}}\f$ be the mean firing rates of the excitatory and inhibitory 
groups, respectively, and let \f$R_{\texttt{exc}}, R_{\texttt{inh}}\f$ be their target firing rates.  
Then the fitness \f$f(\vec{x})\f$ is given by

\f{equation}{
   f(\vec{x}) = \frac{1}{|r_{\texttt{exc}} - R_{\texttt{exc}}| + |r_{\texttt{inh}} - R_{\texttt{inh}}|}. \nonumber
\f}

The point is that the value of \f$f(\vec{x})\f$ increases as the network's behavior approaches the target behavior.

\note ECJ always assumes that we wish to <i>maximize</i> our fitness function. 
If your tuning problem makes more intuitive sense as a minimization problem, you can always throw a 
minus sign on the front to convert one into another.

Using CARLsim3's SpikeMonitor feature, here's what our fitness function looks like in C++:
\code
...
	for(unsigned int i = 0; i < parameters.getNumInstances(); i++) {
		     excMonitor[i]->stopRecording();
		     inhMonitor[i]->stopRecording();

		     excHz[i] = excMonitor[i]->getPopMeanFiringRate();
		     inhHz[i] = inhMonitor[i]->getPopMeanFiringRate();

		     excError[i] = fabs(excHz[i] - EXC_TARGET_HZ);
		     inhError[i] = fabs(inhHz[i] - INH_TARGET_HZ);

		     fitness[i] = 1/(excError[i] + inhError[i]);
		     outputStream << fitness[i] << endl;
	}
	delete network;
	delete in;
}
\endcode

And that wraps up our <tt>run()</tt> method.

\attention Notice that we write the fitness values for each parameter vector directly to the <tt>outputStream</tt>.  
This is important!


\subsection tut7s23_main 7.2.3 The Main Method

With our Experiment class implemented, all that remains is to pull the components provided by PTI together into a 
<tt>main()</tt> method.  The <tt>main()</tt> method we present here is quite generic, and can be used for most any 
parameter-tuning project.

\code
int main(int argc, char* argv[]) {
        /* First we Initialize an Experiment and a PTI object.  The PTI parses CLI
        * arguments, and then loads the Parameters from a file (if one has been
        * specified by the user) or else from a default istream (std::cin here). */
        const TuneFiringRatesECJExperiment experiment;
        const PTI pti(argc, argv, std::cout, std::cin);

	/* The PTI will now cheerfully iterate through all the Parameter sets and
        * run your Experiment on it, printing the results to the specified
        * ostream (std::cout here). */
        pti.runExperiment(experiment);

        return 0;
}
\endcode

The PTI object here does a few different things for you:
-# It checks for a command-line argument of the form "-f filename.csv"
-# If the "-f" argument was found, it parses CSV input from the designated file.  Otherwise, it 
will read CSV input from <tt>std::cin</tt>.
-# It calls the <tt>run()</tt> method of the provided Experiment object, passing it the parsed 
ParameterInstances data and telling it to write the result to <tt>std::cout</tt>.

As mentioned above, if you need to pass some other special data or parameters into your Experiment 
object, then you'll want to customize the construction of the class right here in <tt>main()</tt> method.

We always recommend testing your black-box SNN simulator at the command line with some dummy parameters:
\code
$ for i in {0..9}; do echo "0.$i, 0.$i, 0.$i, 0.$i" >> params.txt; done;
$ make
$ ./tuneFiringRatesECJ -f params.txt
0.0333333
0.13986
0.123457
0.0888889
0.000509775
0.000515943
0.00050958
0.000509346
0.000512308
0.000509528
\endcode


\section tut7s3_ea 7.3 The Evolutionary Algorithm

You don't need to write any Java code to tune %CARLsim models with ECJ.  All you need is an ECJ 
<i>parameter file</i>.  ECJ uses these human-readable files to specify and configure evolutionary 
algorithms by composing a wide variety of algorithmic subcomponents.

The parameter file found at <tt>src/tuneFiringRatesECJExperiment.params</tt> defines a rudimentary 
version of what is known as a \f$(\mu + \lambda)\f$ evolution strategy.  Feel free to copy this file 
and tweak it for use in your own project.  The algorithm it defines works as follows:
-# A population of \f$\mu + \lambda\f$ individuals is randomly initialized.  Here, each individual 
is a vector of real-valued parameters.
-# While the stopping condition is not met,
   -# the \f$\mu\f$ vectors with the highest fitness values are selected to serve as parents,
   -# \f$\lambda\f$ children are created from the parents by copying and mutating them,
   -# and the parents and children together form the population for the next generation.

This is just one of many possible ways that an evolutionary algorithm can be implemented. Here we will 
explain the variables that you can tweak to customize this general algorithm for 
your purposes, but we won't completely explain how ECJ parameter files work.

\note To learn more about ECJ parameter files and the array of algorithms that you can build with them, 
check out the excellent <a href="https://cs.gmu.edu/~eclab/projects/ecj/docs/manual/manual.pdf">ECJ Manual</a>. 
A more in-depth overview of %CARLsim and ECJ (and the extensions CARLsim3 adds to ECJ to help with 
black-box parameter-tuning) can be found in \ref ch10_ecj.


\subsection tut7s31_eaParams 7.3.1 The Evolutionary Parameters

The file opens by importing a standard configuration biolerplate from somewhere deep in ECJ's codebase. This 
just provides some default settings (some of which will be overwritten by the parameters we define below).
\code
# Inherit some boiler-plate configuration
parent.0 =                                              @ec.simple.SimpleEvolutionState simple.params
\endcode

The first section of the parameter file proper tells the evolutionary algorithm when it should stop evolving. 
We want to stop either after 50 generations, or when we find an individual that has a high 
enough fitness value for our purposes, whichever comes first (the threshold for what counts as 
"high enough" will be defined below):

\code
# Stopping Conditions
# =========================
generations =                                           50
# Whether we should stop when the "ideal" individual is found
quit-on-run-complete =                                  true
\endcode

Next we specify that we want to use an initial population size of 10, and that evolution should 
follow a \f$(\mu + \lambda)\f$ model with \f$\mu = \lambda = 5\f$:

\code
# Population and Breeding
# =========================
# Initial population size
pop.subpop.0.size =                                     10

# Evolution strategies options
breed =                                                 ec.es.MuPlusLambdaBreeder
es.mu.0 =                                               5
es.lambda.0 =                                           5
\endcode

\note Finding a good choice of these population parameters tends to be more of an art than a science.  If your 
fitness function turns out to define a very easy (i.e.\ convex, unimodal, noise-free) optimization problem, then a 
\f$(1 + 1)\f$ strategy may work best.  Small populations like that do a lot of "exploitation," and very little 
"exploration" of the parameter space. As a rule of thumb, more complex (i.e.\ rugged, multimodal, noisy) problems are 
more likely to yield to larger population sizes (such as \f$(10 + 10)\f$ or \f$(200 + 200)\f$).  Larger populations 
maintain more diversity, which can help them avoid getting stuck in a local optimum.

\note Either way, it's always a good idea to run your algorithm multiple times.  Since evolutionary algorithms are 
stochastic, the results can differ a great deal from run to run.

Now we define the representation of the individuals we are evolving.  Since we are tuning 4 parameters 
in our CARLsim3 model, we want each individual to have 4 real-valued genes.  We also define minimum and 
maximum values that those genes are allowed to range over.

\code
# Genetic representation
# =========================
pop.subpop.0.species =                                  ec.vector.FloatVectorSpecies
pop.subpop.0.species.ind =                              ec.vector.DoubleVectorIndividual
pop.subpop.0.species.fitness =                          ec.simple.SimpleFitness
pop.subpop.0.species.genome-size =                      4

pop.subpop.0.species.min-gene =                         0.0005
pop.subpop.0.species.max-gene =                         0.5
\endcode

Choosing reasonable bounds for the gene values is an important part of parameter tuning.  The more you 
can narrow down a reasonable range for each gene <i>a priori</i> (for instance, based on your knowledge of 
the neurophysiology of the system you are aiming to model), the easier a time the evolutionary algorithm 
is likely to have searching the parameter space.

\note Here we have defined one range, \f$[0.0005, 0.5]\f$, that applies to all genes.  It is also possible 
to specify bounds for each gene individually, or for segments of genes.  See the 
<a href="https://cs.gmu.edu/~eclab/projects/ecj/docs/manual/manual.pdf">ECJ Manual</a> for more info.

Next we configure selection and mutation.  We give each gene a 25\% probability of being mutated, and 
we use a mutation operator that adds a small amount of Guassian noise to the gene.  We often begin with a 
mutation width (standard deviation) of about 10-20% of the gene's range, and then increase or 
decrease it based on what seems to perform best on our problem.

\code
# Evolutionary operators
# =========================
pop.subpop.0.species.pipe =                             ec.vector.breed.VectorMutationPipeline
pop.subpop.0.species.pipe.source.0 =                    ec.es.ESSelection
pop.subpop.0.species.mutation-prob =                    0.25
pop.subpop.0.species.mutation-type =                    gauss
pop.subpop.0.species.mutation-stdev =                   0.1
pop.subpop.0.species.mutation-bounded =                 true
\endcode

The <tt>mutation-bounded</tt> flag tells the mutation operator that is isn't allowed to mutate a gene outside the 
range we specifed with the <tt>min-gene</tt> and <tt>max-gene</tt> parameters above.

\note A common rule of thumb is to start with a per-gene mutation probability of \f$1/L\f$, where \f$L\f$ is the 
length of your genome.

Finally, we have to tell ECJ about the black-box binary file that defines our fitness function!

\code
# External fitness function
# =========================
eval =                                                  ecjapp.eval.SimpleGroupedEvaluator
eval.problem =                                          ecjapp.eval.problem.CommandProblem
eval.problem.objective =                                ecjapp.eval.problem.objective.StringToDoubleObjective
# The algorithm will stop if this fitness value is reached
eval.problem.objective.idealFitnessValue =              2.0
eval.problem.simulationCommand =                        $tuneFiringRatesECJ
\endcode

These parameters values are not quite standard to ECJ, as they make use of our custom extensions to the evolutionary 
framework (see \ref ch10_ecj).

The <tt>idealFitnessValue</tt> parameter defines our definition of a "perfect" fitness value.  When used in conjunction 
with the <tt>quit-on-run-complete</tt> flag described above, we can tell the algorithm to stop when it finds an 
individual with an ideal fitness value.  Using this feature is purely optional.

The expression <tt>$tuneFiringRatesECJ</tt> tells ECJ to look for a binary file named 
<tt>tuneFiringRatesECJ</tt> in the current directory.


\section tut7s4_output_files 7.4 ECJ Output Files

By default, ECJ produces an <tt>out.stat</tt> file that records the genome and fitness of the best individual 
in each generation.  You can re-run your simulation with the best parameters from the last generation by 
converting the genome to a comma-delimited string and passing it as a file to your black-box simulator:

\code
$ ./launchCARLsimECJ.sh
...
$ tail -n 1 out.stat | sed 's/ /, /g' > best.csv
$ cat best.csv
0.21467680861620786, 0.09693026209578946, 0.05345251635432329, 0.15994428970546937
$ ./tuneFiringRatesECJ -f best.csv 
0.148148
\endcode

\note You may find that running your simulator multiple times with the same genome produces different 
fitness values.  This can often be attributed to the random group-connection mechanism in CARLsim3: 
each time you run the simulation, the precise connectivity pattern between groups is different.

\note In this case, since we only have 10 neurons in each group, our fitness function is very noisy.

\see \ref ch10_ecj

*/
